# 数据预处理

### 读取原始数据集
```python
train_data_path = r'exp1_data\train_data.txt'

corpus = []
with open(train_data_path, 'r') as f:
    lines = f.readlines()
    for line in lines:
        corpus.append(json.loads(line)['raw'])
```
### 去除停用词和标点
使用sklearn内置的停用词和一些标点
```py

# 去除停用词和标点
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

puncs = [',','.','(',')',';',':','[',']','{','}']

corpus = []
for line in corpus_raw:
    filtered_line = []
    words = line.split(' ')
    for word in words:
        if word not in ENGLISH_STOP_WORDS:
            for p in puncs:
                word = word.strip(p)
            filtered_line.append(word)
    corpus.append(filtered_line)
```
### 2-gram分词
使用sklearn的分词工具
'''py
bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),
                                    token_pattern=r'\b\w+\b', min_df=1) # 会提取至少两个字母的单词
analyze = bigram_vectorizer.build_analyzer()
X_2 = bigram_vectorizer.fit_transform(corpus).toarray()
'''
得到的X_2是8000*372129的0-1矩阵。

### Tf-idf
tf-idf的思想是为了防止 “the”, “a”, “is” 等信息含量低的高频词影响频数更少但信息量更高的词。

Tf意为 **term-frequency**，tf-idf意为**term-frequency** times **inverse document-frequency**。
$$
tf-idf(t,d) = 
$$