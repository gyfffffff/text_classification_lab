# 数据预处理

### 读取原始数据集
```python
train_data_path = r'exp1_data\train_data.txt'

corpus = []
with open(train_data_path, 'r') as f:
    lines = f.readlines()
    for line in lines:
        corpus.append(json.loads(line)['raw'])
```
### 去除停用词
使用sklearn内置的停用词和一写
```py
# 去除停用词和标点
puncs = [',','.','(',')',';',':','[',']','{','}']

corpus = []
for line in corpus_raw:
    filtered_line = []
    words = line.split(' ')
    for word in words:
        if word not in ENGLISH_STOP_WORDS:
            for p in puncs:
                word = word.strip(p)
            filtered_line.append(word)
    corpus.append(filtered_line)
```
